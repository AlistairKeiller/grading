{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f660ec-036f-4f3f-a3d2-98f914532e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: peft in ./.local/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: evaluate in ./.local/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: wandb in ./.local/lib/python3.10/site-packages (0.16.6)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from peft) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from peft) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/lib/python3/dist-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (from peft) (4.39.3)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./.local/lib/python3.10/site-packages (from peft) (0.29.2)\n",
      "Requirement already satisfied: safetensors in ./.local/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in ./.local/lib/python3.10/site-packages (from peft) (0.22.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.local/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (from evaluate) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./.local/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in ./.local/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./.local/lib/python3.10/site-packages (from wandb) (1.45.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in ./.local/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (59.6.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/lib/python3/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/lib/python3/dist-packages (from wandb) (4.21.12)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets>=2.0.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.local/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2020.6.20)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers->peft) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install peft wandb sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c5aa79-7d58-48d6-b938-6cb6db95f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd73bf38-92c1-4f50-ad31-764bb3d19f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"learning-agency-lab-automated-essay-scoring-2\", data_files={\"train\": \"train.csv\"})\n",
    "dataset = dataset.rename_column('score', 'labels')\n",
    "dataset = dataset.map(lambda x: {'labels': x['labels'] - 1})\n",
    "dataset = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81a5617-0424-4f85-b36b-a5a0c38f459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e352f6e77740618408342c078b3da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87b9990994f49d0a53415799f2af2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"microsoft/deberta-v3-large\"\n",
    "# MODEL_PATH = \"microsoft/deberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenized_datasets = dataset.map(lambda x: tokenizer(x[\"full_text\"], truncation=True, max_length=None), batched=True, remove_columns=['essay_id', 'full_text'])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    config=AutoConfig.from_pretrained(MODEL_PATH, num_labels=len(set(tokenized_datasets['train']['labels']))),\n",
    ")\n",
    "model = get_peft_model(\n",
    "    model,\n",
    "    LoraConfig(\n",
    "        task_type=\"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd7ed5-0a8e-4e47-b15f-9e6c287e2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malistairkeiller\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/wandb/run-20240417_191240-b1bhiznb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alistairkeiller/huggingface/runs/b1bhiznb' target=\"_blank\">dauntless-dawn-22</a></strong> to <a href='https://wandb.ai/alistairkeiller/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alistairkeiller/huggingface' target=\"_blank\">https://wandb.ai/alistairkeiller/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alistairkeiller/huggingface/runs/b1bhiznb' target=\"_blank\">https://wandb.ai/alistairkeiller/huggingface/runs/b1bhiznb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69897' max='778800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 69897/778800 2:45:57 < 28:03:07, 7.02 it/s, Epoch 8.97/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.017000</td>\n",
       "      <td>0.909018</td>\n",
       "      <td>0.775977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.045600</td>\n",
       "      <td>0.991233</td>\n",
       "      <td>0.808196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.009900</td>\n",
       "      <td>1.140695</td>\n",
       "      <td>0.796862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.042200</td>\n",
       "      <td>1.203605</td>\n",
       "      <td>0.784497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.059600</td>\n",
       "      <td>1.177240</td>\n",
       "      <td>0.808189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.003900</td>\n",
       "      <td>1.309204</td>\n",
       "      <td>0.789138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.953400</td>\n",
       "      <td>1.277670</td>\n",
       "      <td>0.819576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.980900</td>\n",
       "      <td>1.365811</td>\n",
       "      <td>0.808564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,  # Adjust batch size according to your GPU/CPU memory\n",
    "    fp16=True,\n",
    "    num_train_epochs=100\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"qwk\": cohen_kappa_score(predictions, labels, weights='quadratic')}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
